{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import jieba as jb\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import io\n",
    "import time\n",
    "import requests\n",
    "import scipy.spatial\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "\n",
    "import networkx as nx\n",
    "import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundhold = pd.read_csv('data/mutualfundholding.csv')\n",
    "\n",
    "fund = np.array(fundhold)[:, 0]\n",
    "date = np.array(fundhold)[:, 1]\n",
    "stock = np.array(fundhold)[:, 3]\n",
    "value = np.array(fundhold)[:, 4]\n",
    "\n",
    "index = np.where((date >= 20100000) & (date <= 20170000))[0]\n",
    "\n",
    "raw_funds = fund[index]\n",
    "raw_dates = date[index]\n",
    "raw_stocks = stock[index]\n",
    "raw_values = value[index]\n",
    "\n",
    "set_funds = set()\n",
    "set_dates = set()\n",
    "set_stocks = set()\n",
    "for fund in raw_funds:\n",
    "    if fund not in set_funds:\n",
    "        set_funds.add(fund)\n",
    "for date in raw_dates:\n",
    "    if date not in set_dates:\n",
    "        set_dates.add(date)\n",
    "for stock in raw_stocks:\n",
    "    if stock not in set_stocks:\n",
    "        set_stocks.add(stock)\n",
    "\n",
    "list_funds = list(set_funds)\n",
    "list_stocks = list(set_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_date = []\n",
    "for year in range(20100000, 20170000, 10000):\n",
    "    for month_day in [0, 400, 700, 1000]:\n",
    "        select_date.append(year+month_day)\n",
    "select_date = np.array(select_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = np.zeros((len(select_date), len(set_stocks), len(set_funds)))\n",
    "for ind in range(len(raw_funds)):\n",
    "    fund_index = list_funds.index(raw_funds[ind])\n",
    "    stock_index = list_stocks.index(raw_stocks[ind])\n",
    "    time_index = np.where(select_date < raw_dates[ind])[0][-1]\n",
    "    weight_matrix[time_index, stock_index, fund_index] = raw_values[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Data Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_K_line\n",
      "02_bias\n",
      "03_ROC\n",
      "04_amplitude\n",
      "05_MACD\n",
      "06_K_line_combination\n",
      "07_stock_short_high_point\n",
      "08_short_low_point\n",
      "09_middle_high_point\n",
      "10_middle_low_point\n"
     ]
    }
   ],
   "source": [
    "rootDir = '/data/AMC/06_stock_price_weekly/'\n",
    "paths = []\n",
    "for file_name in os.listdir(rootDir):\n",
    "    paths.append(os.path.join(rootDir, file_name))\n",
    "paths.sort()\n",
    "price_file = pd.DataFrame()\n",
    "for path in paths:\n",
    "    csv_price = pd.read_csv(path, encoding='gbk')\n",
    "    price_file = pd.concat([price_file, csv_price], ignore_index=True)\n",
    "\n",
    "rootDir = '/data/AMC/03_stock_features_daily/'\n",
    "fac_file = []\n",
    "dir_name_list = list(os.listdir(rootDir))\n",
    "dir_name_list.sort()\n",
    "for dir_name in dir_name_list:\n",
    "    print(dir_name)\n",
    "    fac_dir = os.path.join(rootDir, dir_name)\n",
    "    paths = []\n",
    "    for file_name in os.listdir(fac_dir):\n",
    "        paths.append(os.path.join(fac_dir, file_name))\n",
    "    paths.sort()\n",
    "    fea_file = pd.DataFrame()\n",
    "    for path in paths:\n",
    "        csv_price = pd.read_csv(path, encoding='gbk')\n",
    "        fea_file = pd.concat([fea_file, csv_price])\n",
    "    fac_file.append(fea_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rootDir = '/data/AMC/06_stock_price_weekly/'\n",
    "paths = []\n",
    "file_name = os.listdir(rootDir)[0]\n",
    "path = os.path.join(rootDir, file_name)\n",
    "csv_price = pd.read_csv(path, encoding='gbk')\n",
    "price_columns = csv_price.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'FirstIndustryCode', u'TradingDay', u'FirstIndustryName', u'SecuCode',\n",
       "       u'SecuAbbr', u'PrevClosePrice', u'OpenPrice', u'HighPrice', u'LowPrice',\n",
       "       u'ClosePrice', u'TurnoverVolume', u'TurnoverValue', u'TurnoverDeals',\n",
       "       u'TotalMV', u'IfWeekEnd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "dict_all = {}\n",
    "a_price_file = np.array(price_file)\n",
    "while index < a_price_file.shape[0]:\n",
    "    index_tmp = np.where(a_price_file[:, 3] == a_price_file[index, 3])[0]\n",
    "    dict_all[a_price_file[index, 3]] = a_price_file[index_tmp, :]\n",
    "    index = index_tmp[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_price = dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {}\n",
    "for fac in fac_file:\n",
    "    index = 0\n",
    "    a_fac = np.array(fac)\n",
    "    while index < a_fac.shape[0]:\n",
    "        index_tmp = np.where(a_fac[:, 3] == a_fac[index, 3])[0]\n",
    "        if a_fac[index, 3] not in dict_feature:\n",
    "            dict_feature[a_fac[index, 3]] = []\n",
    "        dict_feature[a_fac[index, 3]].append(a_fac[index_tmp, :])\n",
    "        index = index_tmp[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature_concat = {}\n",
    "for it in dict_feature:\n",
    "    if len(dict_feature[it]) != 10:\n",
    "        continue\n",
    "    if dict_feature[it][0].shape[0] != 2874:\n",
    "        continue\n",
    "    tmp = dict_feature[it][0][:, 1]\n",
    "    tmp = tmp[:, np.newaxis].astype(str)\n",
    "    dict_feature_concat[it] = tmp\n",
    "    \n",
    "    for it2 in dict_feature[it]:\n",
    "        dict_feature_concat[it] = np.concatenate((dict_feature_concat[it], it2[:, 5:-2]), axis=1)\n",
    "    dict_feature_concat[it] = np.delete(dict_feature_concat[it], 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in dict_feature_concat:\n",
    "    if it not in dict_price:\n",
    "        continue\n",
    "    pd.DataFrame(dict_feature_concat[it], columns=feature_columns).to_csv('stock_data/'+str(it)+'_feature.csv', encoding='GBK', index=False)\n",
    "    pd.DataFrame(dict_price[it], columns=price_columns).to_csv('stock_data/'+str(it)+'_price.csv', encoding='GBK', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start_date, end_date, stock_code):\n",
    "    price_csv = pd.read_csv('stock_data/'+str(stock_code)+'_price.csv')\n",
    "    dates = np.array(price_csv['TradingDay'])\n",
    "    for count in range(len(dates)):\n",
    "        dates[count] = int(''.join(str(dates[count]).split()[0].split('-')))\n",
    "    select_index = np.where((dates >= start_date) & (dates < end_date))[0]\n",
    "    return_price = np.array(price_csv['ClosePrice'][select_index])\n",
    "    \n",
    "    feature_csv = pd.read_csv('stock_data/'+str(stock_code)+'_feature.csv')\n",
    "    dates = np.array(feature_csv['trading_day'])\n",
    "    for count in range(len(dates)):\n",
    "        dates[count] = int(''.join(str(dates[count]).split()[0].split('-')))\n",
    "    select_index = np.where((dates >= start_date) & (dates < end_date))[0]\n",
    "    return_feature = np.array(feature_csv)[select_index, 1:]  \n",
    "    \n",
    "    return return_price, return_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_csv = pd.read_csv('stock_data/'+str(158)+'_feature.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Season Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = []\n",
    "for year in range(2006, 2017):\n",
    "    for month in [0, 400, 700, 1000]:\n",
    "        season.append(year*10000+month)\n",
    "season.append(20170000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in dict_feature_concat:\n",
    "    if it not in dict_price:\n",
    "        continue\n",
    "    season_data = np.zeros((len(season)-1, 45))\n",
    "    for season_id in range(len(season)-1):\n",
    "        a_price, a_feature = get_data(season[season_id], season[season_id+1], it)\n",
    "        average_feature = a_feature[0]\n",
    "        average_price = a_price.mean()\n",
    "        for idx in range(len(a_feature)):\n",
    "            average_feature = 0.4 * average_feature + 0.6 * a_feature[idx]\n",
    "        season_data[season_id, 0] = average_price\n",
    "        season_data[season_id, 1:] = average_feature\n",
    "    pd.DataFrame(season_data).to_csv('stock_data/'+str(it)+'_SeasonAll.csv', encoding='GBK', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], shape=(0, 44), dtype=object))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(season[season_id], season[season_id+1], it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20060000,\n",
       " 20060400,\n",
       " 20060700,\n",
       " 20061000,\n",
       " 20070000,\n",
       " 20070400,\n",
       " 20070700,\n",
       " 20071000,\n",
       " 20080000,\n",
       " 20080400,\n",
       " 20080700,\n",
       " 20081000,\n",
       " 20090000,\n",
       " 20090400,\n",
       " 20090700,\n",
       " 20091000,\n",
       " 20100000,\n",
       " 20100400,\n",
       " 20100700,\n",
       " 20101000,\n",
       " 20110000,\n",
       " 20110400,\n",
       " 20110700,\n",
       " 20111000,\n",
       " 20120000,\n",
       " 20120400,\n",
       " 20120700,\n",
       " 20121000,\n",
       " 20130000,\n",
       " 20130400,\n",
       " 20130700,\n",
       " 20131000,\n",
       " 20140000,\n",
       " 20140400,\n",
       " 20140700,\n",
       " 20141000,\n",
       " 20150000,\n",
       " 20150400,\n",
       " 20150700,\n",
       " 20151000,\n",
       " 20160000,\n",
       " 20160400,\n",
       " 20160700,\n",
       " 20161000,\n",
       " 20170000]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2874"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_feature[1][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2972"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "len(os.listdir('data/stock_price'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
