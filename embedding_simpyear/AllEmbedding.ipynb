{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from datum import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "%matplotlib inline \n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "#有中文出现的情况，需要u'内容'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Datum()\n",
    "data.data_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = data.weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 3145, 2199)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix_all = np.sum(weight_matrix[24:], axis=0)\n",
    "year_index = np.array(range(25, 44, 2))\n",
    "weight_matrix_year = np.sum(weight_matrix[year_index], axis=0)\n",
    "\n",
    "weight_matrix[24:].shape\n",
    "\n",
    "weight_matrix[year_index].shape\n",
    "\n",
    "stable_stock_code = set()\n",
    "for filename in os.listdir('data/select_stock_data'):\n",
    "    code = filename.split('_')[0]\n",
    "    for _ in range(6-len(code)):\n",
    "        code = '0' + code     \n",
    "    if code in stable_stock_code:\n",
    "        continue\n",
    "    else:\n",
    "        stable_stock_code.add(code)\n",
    "\n",
    "stable_index = []\n",
    "for idx, stock in enumerate(data.list_stocks):\n",
    "    if stock in stable_stock_code:\n",
    "        stable_index.append(idx)\n",
    "stable_index = np.array(stable_index)\n",
    "\n",
    "weight_matrix_all = weight_matrix_all[stable_index, :]\n",
    "weight_matrix_year = weight_matrix_year[stable_index, :]\n",
    "\n",
    "weight_matrix_all.shape\n",
    "\n",
    "weight_matrix_year.shape\n",
    "\n",
    "list_stable_stocks = [data.list_stocks[i] for i in stable_index]\n",
    "\n",
    "len(list_stable_stocks)\n",
    "\n",
    "for weight_index, weight in enumerate([weight_matrix_all]):\n",
    "    arr_tmp = []\n",
    "    for stock_index in range(len(list_stable_stocks)):\n",
    "        a_edge_index = np.where(weight[stock_index] != 0)[0]\n",
    "        for edge_index in a_edge_index:\n",
    "            arr_tmp.append([stock_index, len(list_stable_stocks) + edge_index, weight[stock_index, edge_index]])\n",
    "    arr_tmp = np.array(arr_tmp)\n",
    "    pd_tmp = pd.DataFrame(arr_tmp)\n",
    "    pd_tmp[0] = pd_tmp[0].astype(int)\n",
    "    pd_tmp[1] = pd_tmp[1].astype(int)\n",
    "    pd_tmp.to_csv('data/graph/graph_stable_all.csv', index=False, sep=' ')\n",
    "\n",
    "for weight_index, weight in enumerate([weight_matrix_year]):\n",
    "    arr_tmp = []\n",
    "    for stock_index in range(len(list_stable_stocks)):\n",
    "        a_edge_index = np.where(weight[stock_index] != 0)[0]\n",
    "        for edge_index in a_edge_index:\n",
    "            arr_tmp.append([stock_index, len(list_stable_stocks) + edge_index, weight[stock_index, edge_index]])\n",
    "    arr_tmp = np.array(arr_tmp)\n",
    "    pd_tmp = pd.DataFrame(arr_tmp)\n",
    "    pd_tmp[0] = pd_tmp[0].astype(int)\n",
    "    pd_tmp[1] = pd_tmp[1].astype(int)\n",
    "    pd_tmp.to_csv('data/graph/graph_stable_year.csv', index=False, sep=' ')\n",
    "\n",
    "path = os.path.join('data/graph/graph_stable_all.csv')\n",
    "nx_G = nx.read_edgelist(path, nodetype=int, data=(('weight', float),), create_using=nx.DiGraph())\n",
    "nx_G = nx_G.to_undirected()\n",
    "G = graph.Graph(nx_G, False, 1, 1)\n",
    "G.preprocess_transition_probs()\n",
    "\n",
    "walks = G.simulate_walks(50, 200)\n",
    "\n",
    "walks = [list(map(str, walk)) for walk in walks]\n",
    "\n",
    "model = Word2Vec(walks, size=32, window=6, min_count=0, sg=1, workers=2, iter=10)\n",
    "\n",
    "model.wv.save_word2vec_format('data/embedding/stable_embedding_all.emb')\n",
    "\n",
    "path = os.path.join('data/graph/graph_stable_year.csv')\n",
    "nx_G = nx.read_edgelist(path, nodetype=int, data=(('weight', float),), create_using=nx.DiGraph())\n",
    "nx_G = nx_G.to_undirected()\n",
    "G = graph.Graph(nx_G, False, 1, 1)\n",
    "G.preprocess_transition_probs()\n",
    "\n",
    "walks = G.simulate_walks(50, 200)\n",
    "\n",
    "walks = [list(map(str, walk)) for walk in walks]\n",
    "\n",
    "model = Word2Vec(walks, size=32, window=6, min_count=0, sg=1, workers=2, iter=10)\n",
    "\n",
    "model.wv.save_word2vec_format('data/embedding/stable_embedding_year.emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_cluster(filename):\n",
    "    path = os.path.join('data/embedding/', filename+'.emb')\n",
    "    emb_raw = pd.read_csv(path, header=None, sep=' ', skiprows=1)\n",
    "    emb_raw = np.array(emb_raw)\n",
    "    emb = np.zeros((emb_raw.shape[0], emb_raw.shape[1]-1))\n",
    "    for idx, ele in enumerate(emb_raw):\n",
    "        emb[idx] = ele[1:]  \n",
    "    af = AffinityPropagation(preference=-50).fit(emb)\n",
    "    distance = np.zeros((emb.shape[0], emb.shape[0]))\n",
    "    for i in range(emb.shape[0]):\n",
    "        for j in range(emb.shape[0]):\n",
    "            distance[i][j] = np.linalg.norm(emb[i]-emb[j])\n",
    "    f = open(filename+'.txt', 'w')\n",
    "    cluster_num = 0\n",
    "    for idx in af.cluster_centers_indices_:\n",
    "        f.write('new cluster\\n')\n",
    "        cluster_idx = np.where(af.labels_ == af.labels_[idx])[0]\n",
    "        sli = distance[idx]\n",
    "        arg_rank = np.argsort(sli[cluster_idx])\n",
    "        for arg in arg_rank:\n",
    "            arg_true = cluster_idx[arg]\n",
    "            if arg_true >= len(data.use_index):\n",
    "                continue\n",
    "            code = data.list_stocks[use_index][arg_true]       \n",
    "            try:\n",
    "                name = data.dict_code2name[code].split(';')[-2]\n",
    "            except:\n",
    "                name = 'Not know'\n",
    "            f.write(str(cluster_num)+','+str(arg_true)+', '+code+', '+name+'\\n')\n",
    "        cluster_num = cluster_num + 1\n",
    "        f.write('\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start_date, end_date, stock_code):\n",
    "    price_csv = pd.read_csv('data/stock_data/'+str(stock_code)+'_price.csv')\n",
    "    dates = np.array(price_csv['TradingDay'])\n",
    "    for count in range(len(dates)):\n",
    "        dates[count] = int(''.join(str(dates[count]).split()[0].split('-')))\n",
    "    select_index = np.where((dates >= start_date) & (dates < end_date))[0]\n",
    "    return_price = np.array(price_csv['ClosePrice'][select_index])\n",
    "    \n",
    "    feature_csv = pd.read_csv('data/stock_data/'+str(stock_code)+'_feature.csv')\n",
    "    dates = np.array(feature_csv['trading_day'])\n",
    "    for count in range(len(dates)):\n",
    "        dates[count] = int(''.join(str(dates[count]).split()[0].split('-')))\n",
    "    select_index = np.where((dates >= start_date) & (dates < end_date))[0]\n",
    "    return_feature = np.array(feature_csv)[select_index, 1:]  \n",
    "    \n",
    "    return return_price, return_feature\n",
    "\n",
    "num_set = set()\n",
    "for filename in os.listdir('data/stock_data/'):\n",
    "    num = filename.split('_')[0]\n",
    "    if num in num_set:\n",
    "        continue\n",
    "    else:\n",
    "        num_set.add(num) \n",
    "data = Datum()\n",
    "data.data_prepare()  \n",
    "# stock select: 2016,2015...\n",
    "# season_select: all, year\n",
    "# emb_start:2012, 2013...\n",
    "def embedding(emb_start='None', stock_select='None', season_select='all'):\n",
    "    if stock_select != 'None':\n",
    "        stock_select = int(stock_select)\n",
    "        day_feature = get_data(stock_select*10000, 20180000, 1)[1].shape[0]\n",
    "        day_price = get_data(stock_select*10000, 20180000, 1)[0].shape[0]\n",
    "        select_num_set = set()\n",
    "        for num in num_set:\n",
    "            price, feature = get_data(stock_select*10000, 20180000, int(num))\n",
    "            if price.shape[0] == day_price and feature.shape[0] == day_feature:\n",
    "                select_num_set.add(num)   \n",
    "    else:\n",
    "        stock_select = 'all'\n",
    "        select_num_set = num_set\n",
    "    \n",
    "   \n",
    "    \n",
    "    stable_stock_code = set()\n",
    "    for num in select_num_set:\n",
    "        code = num\n",
    "        for _ in range(6-len(code)):\n",
    "            code = '0' + code     \n",
    "        if code in stable_stock_code:\n",
    "            continue\n",
    "        else:\n",
    "            stable_stock_code.add(code)    \n",
    "    \n",
    "    stable_index = []\n",
    "    for idx, stock in enumerate(data.list_stocks):\n",
    "        if stock in stable_stock_code:\n",
    "            stable_index.append(idx)\n",
    "    stable_index = np.array(stable_index)    \n",
    "    data.use_index = stable_index\n",
    "    list_stable_stocks = [data.list_stocks[i] for i in stable_index]   \n",
    "    \n",
    "    weight_matrix = np.copy(data.weight_matrix)\n",
    "    if emb_start != 'None':\n",
    "        emb_start = int(emb_start)\n",
    "        if season_select == 'all':\n",
    "            weight_matrix_total = np.sum(weight_matrix[list(data.select_date).index(emb_start*10000):], axis=0)\n",
    "            print(weight_matrix[list(data.select_date).index(emb_start*10000):].shape)\n",
    "        else:\n",
    "            index = np.array(range(list(data.select_date).index(emb_start*10000)+1, 44, 2))\n",
    "            weight_matrix_total = np.sum(weight_matrix[index], axis=0)\n",
    "            print(weight_matrix[index].shape)\n",
    "    else:\n",
    "        emb_start = 'all'\n",
    "        if season_select == 'all':\n",
    "            weight_matrix_total = np.sum(weight_matrix, axis=0)\n",
    "            print(weight_matrix.shape)\n",
    "        else:\n",
    "            index = np.array(range(1, 44, 2))\n",
    "            weight_matrix_total = np.sum(weight_matrix[index], axis=0)\n",
    "            print(weight_matrix[index].shape)        \n",
    "\n",
    "    weight_matrix_total = weight_matrix_total[stable_index, :]\n",
    "\n",
    "    for weight_index, weight in enumerate([weight_matrix_total]):\n",
    "        arr_tmp = []\n",
    "        for stock_index in range(len(list_stable_stocks)):\n",
    "            a_edge_index = np.where(weight[stock_index] != 0)[0]\n",
    "            for edge_index in a_edge_index:\n",
    "                arr_tmp.append([stock_index, len(list_stable_stocks) + edge_index, weight[stock_index, edge_index]])\n",
    "        arr_tmp = np.array(arr_tmp)\n",
    "        pd_tmp = pd.DataFrame(arr_tmp)\n",
    "        pd_tmp[0] = pd_tmp[0].astype(int)\n",
    "        pd_tmp[1] = pd_tmp[1].astype(int)\n",
    "        pd_tmp.to_csv('data/graph/graph_{}_{}_{}.csv'.format(emb_start, stock_select, season_select), index=False, sep=' ')\n",
    "\n",
    "\n",
    "        path = 'data/graph/graph_{}_{}_{}.csv'.format(emb_start, stock_select, season_select)\n",
    "        nx_G = nx.read_edgelist(path, nodetype=int, data=(('weight', float),), create_using=nx.DiGraph())\n",
    "        nx_G = nx_G.to_undirected()\n",
    "        G = graph.Graph(nx_G, False, 1, 1)\n",
    "        G.preprocess_transition_probs()\n",
    "\n",
    "        walks = G.simulate_walks(50, 200)\n",
    "        walks = [list(map(str, walk)) for walk in walks]\n",
    "        model = Word2Vec(walks, size=32, window=6, min_count=0, sg=1, workers=2, iter=10)\n",
    "        model.wv.save_word2vec_format('data/embedding/embedding_{}_{}_{}.emb'.format(emb_start, stock_select, season_select))\n",
    "        \n",
    "    embedding_cluster('embedding_{}_{}_{}.emb'.format(emb_start, stock_select, season_select))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3145, 2199)\n",
      "Walk iteration:\n",
      "('1', '/', '50')\n",
      "('2', '/', '50')\n",
      "('3', '/', '50')\n",
      "('4', '/', '50')\n",
      "('5', '/', '50')\n",
      "('6', '/', '50')\n",
      "('7', '/', '50')\n",
      "('8', '/', '50')\n",
      "('9', '/', '50')\n",
      "('10', '/', '50')\n",
      "('11', '/', '50')\n",
      "('12', '/', '50')\n",
      "('13', '/', '50')\n",
      "('14', '/', '50')\n",
      "('15', '/', '50')\n",
      "('16', '/', '50')\n",
      "('17', '/', '50')\n",
      "('18', '/', '50')\n",
      "('19', '/', '50')\n",
      "('20', '/', '50')\n",
      "('21', '/', '50')\n",
      "('22', '/', '50')\n",
      "('23', '/', '50')\n",
      "('24', '/', '50')\n",
      "('25', '/', '50')\n",
      "('26', '/', '50')\n",
      "('27', '/', '50')\n",
      "('28', '/', '50')\n",
      "('29', '/', '50')\n",
      "('30', '/', '50')\n",
      "('31', '/', '50')\n",
      "('32', '/', '50')\n",
      "('33', '/', '50')\n",
      "('34', '/', '50')\n",
      "('35', '/', '50')\n",
      "('36', '/', '50')\n",
      "('37', '/', '50')\n",
      "('38', '/', '50')\n",
      "('39', '/', '50')\n",
      "('40', '/', '50')\n",
      "('41', '/', '50')\n",
      "('42', '/', '50')\n",
      "('43', '/', '50')\n",
      "('44', '/', '50')\n",
      "('45', '/', '50')\n",
      "('46', '/', '50')\n",
      "('47', '/', '50')\n",
      "('48', '/', '50')\n",
      "('49', '/', '50')\n",
      "('50', '/', '50')\n"
     ]
    }
   ],
   "source": [
    "embedding(2016, 0, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
